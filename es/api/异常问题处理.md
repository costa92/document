# es 索引异常处理

集群 RED 和 YELLOW 是 Elasticsearch 集群最常见的问题之一，无论 RED 还是 YELLOW，原因只有一个：有部分分片没有分配。

如果有一个以上的主分片没有被分配，集群以及相关索引被标记为 RED 状态，如果所有主分片都已成功分配，有部分副分片没有被分配，集群以及相关索引被标记为 YELLOW 状态。

对于集群 RED 或 YELLOW 的问题诊断推荐使用 Cluster Allocation Explain API，该 API 可以给出造成分片未分配的具体原因。例如，如下请求可以返回第一个未分配的分片的具体原因：

```bash
GET /_cluster/allocation/explain
```

也可以只查看特定分片未分配的原因：

```bash
GET /_cluster/allocation/explain
{
  "index": "myindex",
  "shard": 0,
  "primary": true
}
```
引用一个官网的例子，API 的返回信息如下：

```bash
{
  "index" : "idx",
  "shard" : 0,
  "primary" : true,
  "current_state" : "unassigned",                 
  "unassigned_info" : {
    "reason" : "INDEX_CREATED",                   
    "at" : "2017-01-04T18:08:16.600Z",
    "last_allocation_status" : "no"
  },
  "can_allocate" : "no",                          
  "allocate_explanation" : "cannot allocate because allocation is not permitted to any of the nodes",
  "node_allocation_decisions" : [
    {
      "node_id" : "8qt2rY-pT6KNZB3-hGfLnw",
      "node_name" : "node-0",
      "transport_address" : "127.0.0.1:9401",
      "node_attributes" : {},
      "node_decision" : "no",                     
      "weight_ranking" : 1,
      "deciders" : [
        {
          "decider" : "filter",                   
          "decision" : "NO",
          "explanation" : "node does not match index setting [index.routing.allocation.include] filters [_name:\"non_existent_node\"]"  
        }
      ]
    }
  ]
}
```

在返回结果中给出了导致分片未分配的详细信息，reason 给出了分片最初未分配的原因，可以理解成 unassigned 是什么操作触发的；allocate_explanation则进一步的说明，该分片无法被分配到任何节点，而无法分配的具体原因在 deciders 的 explanation 信息中详细描述。这些信息足够我们诊断问题。

1. INDEX_CREATED

由于 create index api 创建索引导致，索引创建过程中，把索引的全部分片分配完毕需要一个过程，在全部分片分配完毕之前，该索引会处于短暂的 RED 或 YELLOW 状态。因此监控系统如果发现集群 RED，不一定代表出现了故障。

2. CLUSTER_RECOVERED

集群完全重启时，所有分片都被标记为未分配状态，因此在集群完全重启时的启动阶段，reason属于此种类型。

3. INDEX_REOPENED

open 一个之前 close 的索引， reopen 操作会将索引分配重新分配。

4. DANGLING_INDEX_IMPORTED

正在导入一个 dangling index，什么是 dangling index？

磁盘中存在，而集群状态中不存在的索引称为 dangling index，例如从别的集群拷贝了一个索引的数据目录到当前集群，Elasticsearch 会将这个索引加载到集群中，因此会涉及到为 dangling index 分配分片的过程。

5. NEW_INDEX_RESTORED

从快照恢复到一个新索引。

6. EXISTING_INDEX_RESTORED,

从快照恢复到一个关闭状态的索引。

7. REPLICA_ADDED

增加分片副本。

8. ALLOCATION_FAILED

由于分配失败导致。

9. NODE_LEFT

由于节点离线。

10. REROUTE_CANCELLED

由于显式的cancel reroute命令。

11. REINITIALIZED

由于分片从 started 状态转换到 initializing 状态。

12. REALLOCATED_REPLICA

由于迁移分片副本。

13. PRIMARY_FAILED

初始化副分片时，主分片失效。

14. FORCED_EMPTY_PRIMARY

强制分配一个空的主分片。

15. MANUAL_ALLOCATION



## 解决方式

对于不同原因导致的未分配要采取对应的处理措施，因此需要具体问题具体分析。需要注意的是每个索引也有 GREEN，YELLOW，RED 状态，只有全部索引都 GREEN 时集群才 GREEN，只要有一个索引 RED 或 YELLOW，集群就会处于 RED 或 YELLOW。如果是一些测试索引导致的 RED，你直接简单地删除这个索引。

因此单个的未分配分片就会导致集群 RED 或 YELLOW，一些常见的未分配原因如下：

由于配置问题导致的，需要修正相应的配置
由于节点离线导致的，需要重启离线的节点
由于分片规则限制的，例如 total_shards_per_node，或磁盘剩余空间限制等，需要调整相应的规则
分配主分片时，由于找不到最新的分片数据，导致主分片未分配，这种要观察是否有节点离线，极端情况下只能手工分片陈旧的分片为主分片，这会导致丢失一些新入库的数据。
集群 RED 或 YELLOW 时，一般我们首先需要看一下是否有节点离线，对于节点无法启动或无法加入集群的问题我们单独讨论。下面我们分享一些 RED 与 YELLOW 的案例及相应的处理方式。



### 问题一 index 状态一直为 yellow 状态

出现：explanation 字段出现：cannot allocate because allocation is not permitted to any of the nodes

分析原因：
    
```bash
_cluster/allocation/explain
```

输入结果：
```
{
  "index" : "home_address",
  "shard" : 0,
  "primary" : true,
  "current_state" : "started",
  "current_node" : {
    "id" : "dbJpDVPBTaWg2rgTPkeQtg",
    "name" : "elk02",
    "transport_address" : "192.168.11.166:9300",
    "attributes" : {
      "ml.machine_memory" : "12428537856",
      "ml.max_open_jobs" : "20",
      "xpack.installed" : "true"
    },
    "weight_ranking" : 2
  },
  "can_remain_on_current_node" : "yes",
  "can_rebalance_cluster" : "throttled",
  "can_rebalance_cluster_decisions" : [
    {
      "decider" : "concurrent_rebalance",
      "decision" : "THROTTLE",
      "explanation" : "reached the limit of concurrently rebalancing shards [2], cluster setting [cluster.routing.allocation.cluster_concurrent_rebalance=2]"
    }
  ],
  "can_rebalance_to_other_node" : "throttled",
  "rebalance_explanation" : "rebalancing is throttled",
  "node_allocation_decisions" : [
    {
      "node_id" : "xd2hDem9RcyXe3vGjzb-zQ",
      "node_name" : "elk01",
      "transport_address" : "192.168.11.165:9300",
      "node_attributes" : {
        "ml.machine_memory" : "12428701696",
        "xpack.installed" : "true",
        "ml.max_open_jobs" : "20"
      },
      "node_decision" : "no",
      "weight_ranking" : 1,
      "deciders" : [
        {
          "decider" : "same_shard",
          "decision" : "NO",
          "explanation" : "the shard cannot be allocated to the same node on which a copy of the shard already exists [[home_address][0], node[xd2hDem9RcyXe3vGjzb-zQ], [R], s[STARTED], a[id=pJalhIkiS4KbljNONjpXmw]]"
        },
        {
          "decider" : "throttling",
          "decision" : "THROTTLE",
          "explanation" : "reached the limit of incoming shard recoveries [2], cluster setting [cluster.routing.allocation.node_concurrent_incoming_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])"
        }
      ]
    },
    {
      "node_id" : "y7nmnS0dQamQv_KiwX1R1Q",
      "node_name" : "elk03",
      "transport_address" : "192.168.11.167:9300",
      "node_attributes" : {
        "ml.machine_memory" : "12428619776",
        "ml.max_open_jobs" : "20",
        "xpack.installed" : "true"
      },
      "node_decision" : "no",
      "weight_ranking" : 2,
      "deciders" : [
        {
          "decider" : "same_shard",
          "decision" : "NO",
          "explanation" : "the shard cannot be allocated to the same node on which a copy of the shard already exists [[home_address][0], node[y7nmnS0dQamQv_KiwX1R1Q], [R], s[STARTED], a[id=c8lHC457RCub2o7RuPlcJA]]"
        },
        {
          "decider" : "throttling",
          "decision" : "THROTTLE",
          "explanation" : "reached the limit of outgoing shard recoveries [2] on the node [dbJpDVPBTaWg2rgTPkeQtg] which holds the primary, cluster setting [cluster.routing.allocation.node_concurrent_outgoing_recoveries=2] (can also be set via [cluster.routing.allocation.node_concurrent_recoveries])"
        }
      ]
    }
  ]
}

```

解决方法：
```bash
 /_cluster/reroute?retry_failed=true
```

es 的机制貌似是try 5次就停了，重启 master 或 node 都无效，执行上命令才可以 retry


